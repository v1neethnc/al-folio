<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Benchmarking CNNs on Image Classification Task | Vineeth NC</title> <meta name="author" content="Vineeth NC"/> <meta name="description" content="Project to compare the performance of VGG16, VGG19, ResNet50, and ResNet101 on an image classification task."/> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>⚛️</text></svg>"> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://v1neethnc.github.io/projects/2021-09-benchmarking-cnns-classification/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Vineeth </span>NC</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">repositories</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Benchmarking CNNs on Image Classification Task</h1> <p class="post-description">Project to compare the performance of VGG16, VGG19, ResNet50, and ResNet101 on an image classification task.</p> </header> <article> <p><strong>NOTE: This project was done over a duration of 12 weeks to fulfill the Course Project requirement for CMSC 611 - Advanced Computer Architecture at University of Maryland, Baltimore County. The following is a paraphrased version of the 4 page project report that was written in conjunction with two peers: Tejaswini Manjunath, Gaurav Baser.</strong></p> <p>Time Period: September, 2021 – December, 2021 <br><br></p> <h2 id="contents">Contents</h2> <hr> <ul> <li><a href="#introduction">Introduction</a></li> <li><a href="#dataset">Dataset</a></li> <li><a href="#project-approach">Project Approach</a></li> <li> <a href="#experiment">Experiment</a> <ul> <li><a href="#resnet">ResNet</a></li> <li><a href="#vgg">VGG</a></li> </ul> </li> <li> <a href="#results">Results</a> <ul> <li><a href="#accuracy">Accuracy</a></li> <li><a href="#resource-utilization">Resource Utilization</a></li> </ul> </li> <li> <a href="#conclusion">Conclusion</a> <br><br> </li> </ul> <h2 id="introduction">Introduction</h2> <hr> <p>This project is aimed at training different popular CNNs for a multi-class image classification task and check their performance in order to find out the most viable CNN for a given use case in the presence of a specific, limited hardware resources. Benchmarking the performance of CNNs will help in establishing a baseline metric to judge the capabilities of the chosen CNNs. The CNNs chosen for this project are: VGG16, VGG19, ResNet50, ResNet101. <br><br></p> <h2 id="dataset">Dataset</h2> <hr> <p>The training and testing of the models was done on the default architecture that Google Colab provides. To performance a comprehensive evaluation, the ideal dataset is one that contains multiple classes, and has a sizeable training and testing dataset. To this end, the <a href="https://www.kaggle.com/datasets/puneet6060/intel-image-classification" target="_blank" rel="noopener noreferrer">Kaggle Intel Image Classification</a> dataset seemed like the perfect match. This dataset over 14000 training images, and the validation dataset contains over 3000 images. There is a healthy class distribution of the six different classes. For the purposes of this experiment, the batch size was kept constant throughout the training and validation of all the models at 32 images per batch.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/training_distribution-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/training_distribution-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/training_distribution-1400.webp"></source> <img src="/assets/img/vgg_resnet/training_distribution.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Training Distribution" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/validation_distribution-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/validation_distribution-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/validation_distribution-1400.webp"></source> <img src="/assets/img/vgg_resnet/validation_distribution.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Testing Distribution" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> Training Dataset Distribution </div> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> Testing Dataset Distribution </div> </div> <p><br><br></p> <h2 id="project-approach">Project Approach</h2> <hr> <p>To find the best among the aforementioned CNNs, the evaluation is done on two fronts: performance of classification, and the resource utilization metrics. Because of limited resource availability, the training, testing, and the benchmarking are done on Google Colab, where GPU is freely available. The classification performance will include calculating metrics like accuracy, and the resource utilization statistics are computed by wandb.</p> <h2 id="experiment">Experiment</h2> <hr> <h3 id="resnet">ResNet</h3> <p>With a fixed batch size of 32, and images rescaled to 150 x 150, the ResNet50 and ResNet101 models were trained. The accompanying graph shows that the training set loss starts dropping to close to zero. Before the validation loss increases drastically, which signifies that the model is overfitting the training data, the training is stopped. That is why each model is trained for 20 epochs only. The training speed for ResNet50 and ResNet101 is observed to be 433ms/step and 772ms/step respectively.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/resnet50_training_stats-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/resnet50_training_stats-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/resnet50_training_stats-1400.webp"></source> <img src="/assets/img/vgg_resnet/resnet50_training_stats.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ResNet50 Training" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> ResNet50 Training </div> </div> <p><br></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/resnet101_training_stats-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/resnet101_training_stats-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/resnet101_training_stats-1400.webp"></source> <img src="/assets/img/vgg_resnet/resnet101_training_stats.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="ResNet101 Training" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> ResNet101 Training </div> </div> <h3 id="vgg">VGG</h3> <p>The base architecture was kept non-trainable to preserve the Imagenet weights, while new architecture on top of it was subject to the training process. The training images were converted to the standard VG616 sizes, which is 224x224 in 3 color channels. In order to make the best use of time and to avoid overfitting, the training was limited to 20 epochs. During training, it was observed that the training times for VGG16 and VGG19 was 122sec/epoch, where each epoch involved training the model, and calculating loss on validation dataset.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/vgg16_training_graphs-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/vgg16_training_graphs-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/vgg16_training_graphs-1400.webp"></source> <img src="/assets/img/vgg_resnet/vgg16_training_graphs.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="VGG16 Training" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> VGG16 Training </div> </div> <p><br></p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/vgg19_training_graphs-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/vgg19_training_graphs-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/vgg19_training_graphs-1400.webp"></source> <img src="/assets/img/vgg_resnet/vgg19_training_graphs.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="VGG19 Training" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> VGG19 Training </div> </div> <p><br><br></p> <h2 id="results">Results</h2> <hr> <h3 id="accuracy">Accuracy</h3> <p>The accuracy of both the ResNet models is similar with an accuracy of 91.60% for ResNet50 and an accuracy of 92.82% for ResNet101. The accuracy of VGG models are comparable to ResNet with an accuracy of 92.37% for VGG16 and an accuracy of 92.80% for VGG19. The difference in accuracy between the ResNet and VGG models is not very significant.</p> <h3 id="resource-utilization">Resource Utilization</h3> <p>The first stand out observation is that ResNet101 is the longest running model of the lot. The training and validation of the model for 20 epochs takes about 100 minutes, compared to the 40 minutes it takes to train VGG16, 57 minutes to train VGG19, and 71 minutes to train ResNet50. ResNet101 is by far the most complex model in terms of architecture, and consequently takes far more time to train.</p> <p>There is remarkable difference in the ways the models built on these architectures use the resources that they are provided with. The VGG family show a significant variance in GPU usage statistics. While training, the models often have shorts bursts of extreme GPU usage, followed by short spans of zero GPU usage. On the other hand, the ResNet models have a consistent usage of the GPU until the training and the validation process is done. The variance in GPU usage is far less diverse. This is further corroborated by GPU temperature statistics, where the temperature of the GPU is plotted against time taken to train the models. The GPUs are at a consistently higher temperature for the ResNet lines on the graph, while there are significant peaks and lows for the VGG models.</p> <p>While variance in the GPU utilization between VGG and ResNet is already documented, it can be observed that the short bursts of VGG models’ GPU usage often results in a higher amount of GPU being used, while ResNet has a consistent GPU utilization, with their highest being lower than VGG models’ highest.</p> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/vgg_resnet/wandb_stats-480.webp"></source> <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/vgg_resnet/wandb_stats-800.webp"></source> <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/vgg_resnet/wandb_stats-1400.webp"></source> <img src="/assets/img/vgg_resnet/wandb_stats.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="Resource Consumption Statistics" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row"> <div class="col-sm mt-3 mt-md-0" style="text-align: center;vertical-align: middle;"> Resource Consumption Statistics </div> </div> <p><br><br></p> <h2 id="conclusion">Conclusion</h2> <hr> <p>The results show that compared to the ResNet, VGG has better performance in terms of GPU utilization and time. This can be seen in the fact that they are slightly more accurate than the ResNet models while taking lesser execution time. They show higher GPU utilization statistics, which is the desirable scenario when it comes to using GPU for image processing.</p> <p>Such high performance, while being easy-to-use, makes models built on VGG architectures more desirable for a normal end user looking to perform simple image classification tasks.</p> </article> </div> </div> <footer class="sticky-bottom mt-5"> <div class="container"> © Copyright 2023 Vineeth NC. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> </body> </html>